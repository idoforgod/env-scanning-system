#!/usr/bin/env python3
"""
pSRT 2.0 E2E Workflow Validator.

í™˜ê²½ìŠ¤ìºë‹ ì‹œìŠ¤í…œì˜ ì›Œí¬í”Œë¡œìš°ì™€ ì—ì´ì „íŠ¸ ì—°ê²°ì„ ê²€ì¦í•©ë‹ˆë‹¤.
"""

import json
import re
from datetime import datetime
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸
PROJECT_ROOT = Path(__file__).parent.parent

# ê²€ì¦ ê²°ê³¼
results = {"passed": [], "failed": [], "warnings": []}


def log_pass(test_name: str, details: str = "") -> None:
    """Log a passed test result."""
    results["passed"].append({"test": test_name, "details": details})
    print(f"âœ… PASS: {test_name}")
    if details:
        print(f"   â””â”€ {details}")


def log_fail(test_name: str, details: str = "") -> None:
    """Log a failed test result."""
    results["failed"].append({"test": test_name, "details": details})
    print(f"âŒ FAIL: {test_name}")
    if details:
        print(f"   â””â”€ {details}")


def log_warn(test_name: str, details: str = "") -> None:
    """Log a warning."""
    results["warnings"].append({"test": test_name, "details": details})
    print(f"âš ï¸  WARN: {test_name}")
    if details:
        print(f"   â””â”€ {details}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Test 1: ì—ì´ì „íŠ¸ íŒŒì¼ ì¡´ì¬ í™•ì¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def test_agent_files_exist() -> None:
    """PSRT 2.0 ê´€ë ¨ ì—ì´ì „íŠ¸ íŒŒì¼ ì¡´ì¬ í™•ì¸."""
    print("\n" + "=" * 60)
    print("Test 1: Agent Files Existence")
    print("=" * 60)

    required_agents = [
        # pSRT 2.0 Phase ì—ì´ì „íŠ¸
        "groundedness-verifier.md",
        "cross-validator.md",
        "calibration-engine.md",
        "hallucination-detector.md",
        "confidence-evaluator.md",
        # ê¸°ì¡´ ì›Œí¬í”Œë¡œìš° ì—ì´ì „íŠ¸
        "signal-classifier.md",
        "impact-analyzer.md",
        "priority-ranker.md",
        "report-generator.md",
        "db-updater.md",
    ]

    agents_dir = PROJECT_ROOT / ".claude" / "agents"

    for agent in required_agents:
        agent_path = agents_dir / agent
        if agent_path.exists():
            log_pass(f"Agent: {agent}")
        else:
            log_fail(f"Agent: {agent}", f"File not found: {agent_path}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Test 2: ì—ì´ì „íŠ¸ ë©”íƒ€ë°ì´í„° íŒŒì‹±
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def test_agent_metadata() -> None:
    """ì—ì´ì „íŠ¸ íŒŒì¼ì˜ YAML frontmatter íŒŒì‹± ê²€ì¦."""
    print("\n" + "=" * 60)
    print("Test 2: Agent Metadata Parsing")
    print("=" * 60)

    agents_dir = PROJECT_ROOT / ".claude" / "agents"

    pSRT_agents = [
        "groundedness-verifier.md",
        "cross-validator.md",
        "calibration-engine.md",
        "hallucination-detector.md",
        "confidence-evaluator.md",
    ]

    for agent_name in pSRT_agents:
        agent_path = agents_dir / agent_name
        if not agent_path.exists():
            continue

        content = agent_path.read_text()

        # YAML frontmatter íŒŒì‹±
        yaml_match = re.match(r"^---\n(.*?)\n---", content, re.DOTALL)
        if yaml_match:
            yaml_content = yaml_match.group(1)

            # í•„ìˆ˜ í•„ë“œ í™•ì¸
            required_fields = ["name", "description", "tools", "model"]
            missing = []
            for field in required_fields:
                if f"{field}:" not in yaml_content:
                    missing.append(field)

            if missing:
                log_fail(f"Metadata: {agent_name}", f"Missing fields: {missing}")
            else:
                log_pass(f"Metadata: {agent_name}", "All required fields present")
        else:
            log_fail(f"Metadata: {agent_name}", "No YAML frontmatter found")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Test 3: ì›Œí¬í”Œë¡œìš° ì…ì¶œë ¥ ì—°ê²° ê²€ì¦
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def test_workflow_io_connections() -> None:
    """ì—ì´ì „íŠ¸ ê°„ ì…ì¶œë ¥ íŒŒì¼ ì—°ê²° ê²€ì¦."""
    print("\n" + "=" * 60)
    print("Test 3: Workflow I/O Connections")
    print("=" * 60)

    # pSRT 2.0 ì›Œí¬í”Œë¡œìš° ì •ì˜
    pSRT_workflow = {
        "signal-classifier": {
            "inputs": ["data/{date}/filtered/filtered-signals-{date}.json"],
            "outputs": ["data/{date}/structured/structured-signals-{date}.json"],
        },
        "groundedness-verifier": {
            "inputs": ["data/{date}/structured/structured-signals-{date}.json"],
            "outputs": ["data/{date}/analysis/groundedness-scores-{date}.json"],
        },
        "cross-validator": {
            "inputs": [
                "data/{date}/analysis/groundedness-scores-{date}.json",
                "data/{date}/structured/structured-signals-{date}.json",
            ],
            "outputs": ["data/{date}/analysis/cross-validation-{date}.json"],
        },
        "confidence-evaluator": {
            "inputs": [
                "data/{date}/analysis/groundedness-scores-{date}.json",
                "data/{date}/analysis/cross-validation-{date}.json",
                "data/{date}/analysis/calibration-{date}.json",
                "data/{date}/analysis/hallucination-report-{date}.json",
            ],
            "outputs": ["data/{date}/analysis/pSRT-scores-{date}.json", "data/{date}/analysis/final-pSRT-{date}.json"],
        },
        "hallucination-detector": {
            "inputs": [
                "data/{date}/analysis/groundedness-scores-{date}.json",
                "data/{date}/analysis/cross-validation-{date}.json",
                "data/{date}/structured/structured-signals-{date}.json",
            ],
            "outputs": ["data/{date}/analysis/hallucination-report-{date}.json"],
        },
        "calibration-engine": {
            "inputs": ["data/{date}/analysis/pSRT-scores-{date}.json", "signals/history/signal-history.json"],
            "outputs": ["data/{date}/analysis/calibration-{date}.json", "signals/history/signal-history.json"],
        },
    }

    # ì—°ê²° ê²€ì¦
    all_outputs = set()
    all_inputs = set()

    for _agent, io in pSRT_workflow.items():
        for output in io["outputs"]:
            all_outputs.add(output)
        for input_file in io["inputs"]:
            all_inputs.add(input_file)

    # ì…ë ¥ íŒŒì¼ì´ ë‹¤ë¥¸ ì—ì´ì „íŠ¸ì˜ ì¶œë ¥ì¸ì§€ í™•ì¸
    orphan_inputs = []
    for input_file in all_inputs:
        # ì´ˆê¸° ì…ë ¥ ë˜ëŠ” ì™¸ë¶€ íŒŒì¼ì¸ì§€ í™•ì¸
        if input_file not in all_outputs and not any(
            x in input_file for x in ["filtered-signals", "signal-history.json", "source-accuracy", "topic-accuracy"]
        ):
            orphan_inputs.append(input_file)

    if orphan_inputs:
        log_warn("I/O Chain", f"Inputs without producer: {orphan_inputs}")
    else:
        log_pass("I/O Chain", "All inputs have producers or are initial inputs")

    # ê° ì—ì´ì „íŠ¸ì˜ ì—°ê²° í™•ì¸
    for agent, io in pSRT_workflow.items():
        log_pass(f"Agent I/O: {agent}", f"In: {len(io['inputs'])}, Out: {len(io['outputs'])}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Test 4: ì„¤ì • íŒŒì¼ ê²€ì¦
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def test_config_files() -> None:
    """PSRT 2.0 ì„¤ì • íŒŒì¼ ê²€ì¦."""
    print("\n" + "=" * 60)
    print("Test 4: Configuration Files")
    print("=" * 60)

    config_dir = PROJECT_ROOT / "config"

    # pSRT ì„¤ì • íŒŒì¼
    psrt_config = config_dir / "pSRT-config.yaml"
    if psrt_config.exists():
        content = psrt_config.read_text()

        # í•µì‹¬ ì„¹ì…˜ í™•ì¸
        required_sections = [
            "final_pSRT_weights",
            "groundedness",
            "cross_validation",
            "calibration",
            "hallucination_detection",
            "grade_system",
        ]

        missing = [s for s in required_sections if s not in content]
        if missing:
            log_fail("pSRT-config.yaml", f"Missing sections: {missing}")
        else:
            log_pass("pSRT-config.yaml", f"All {len(required_sections)} sections present")
    else:
        log_fail("pSRT-config.yaml", "File not found")

    # pSRT ìŠ¤í‚¤ë§ˆ íŒŒì¼
    psrt_schema = config_dir / "pSRT-schema.json"
    if psrt_schema.exists():
        try:
            schema = json.loads(psrt_schema.read_text())
            if "definitions" in schema:
                log_pass("pSRT-schema.json", f"Valid JSON with {len(schema.get('definitions', {}))} definitions")
            else:
                log_warn("pSRT-schema.json", "No definitions section")
        except json.JSONDecodeError as e:
            log_fail("pSRT-schema.json", f"Invalid JSON: {e}")
    else:
        log_fail("pSRT-schema.json", "File not found")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Test 5: History Database ê²€ì¦
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def test_history_database() -> None:
    """ì—­ì‚¬ì  ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡° ê²€ì¦."""
    print("\n" + "=" * 60)
    print("Test 5: History Database Structure")
    print("=" * 60)

    history_dir = PROJECT_ROOT / "signals" / "history"

    required_files = ["signal-history.json", "source-accuracy.json", "topic-accuracy.json"]

    for filename in required_files:
        filepath = history_dir / filename
        if filepath.exists():
            try:
                data = json.loads(filepath.read_text())
                if "metadata" in data:
                    log_pass(
                        f"History DB: {filename}",
                        f"Valid with metadata (v{data['metadata'].get('schema_version', '?')})",
                    )
                else:
                    log_warn(f"History DB: {filename}", "No metadata section")
            except json.JSONDecodeError as e:
                log_fail(f"History DB: {filename}", f"Invalid JSON: {e}")
        else:
            log_fail(f"History DB: {filename}", "File not found")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Test 6: ì‹¤ì œ ë°ì´í„° ê²€ì¦
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def test_actual_data() -> None:
    """ì‹¤ì œ ë°ì´í„° íŒŒì¼ ê²€ì¦."""
    print("\n" + "=" * 60)
    print("Test 6: Actual Data Validation")
    print("=" * 60)

    # database.json ê²€ì¦
    db_path = PROJECT_ROOT / "signals" / "database.json"
    if db_path.exists():
        try:
            db = json.loads(db_path.read_text())
            total = db.get("metadata", {}).get("total_signals", 0)
            log_pass("database.json", f"Valid with {total} signals")

            # ì‹ í˜¸ êµ¬ì¡° ìƒ˜í”Œ ê²€ì¦
            signals = db.get("signals", [])
            if signals:
                sample = signals[0]
                required_fields = ["id", "category", "title", "significance"]
                missing = [f for f in required_fields if f not in sample]
                if missing:
                    log_warn("Signal structure", f"Missing fields in sample: {missing}")
                else:
                    log_pass("Signal structure", "Sample signal has required fields")
        except json.JSONDecodeError as e:
            log_fail("database.json", f"Invalid JSON: {e}")
    else:
        log_fail("database.json", "File not found")

    # ìµœì‹  ë‚ ì§œ ë°ì´í„° í™•ì¸
    data_dir = PROJECT_ROOT / "data" / "2026" / "01" / "14"
    if data_dir.exists():
        structured = data_dir / "structured" / "structured-signals-2026-01-14.json"
        if structured.exists():
            try:
                data = json.loads(structured.read_text())
                count = len(data.get("signals", []))
                log_pass("Latest structured data", f"2026-01-14: {count} signals")
            except json.JSONDecodeError as e:
                log_fail("Latest structured data", f"Invalid JSON: {e}")
        else:
            log_warn("Latest structured data", "No structured signals file")
    else:
        log_warn("Latest data directory", "2026-01-14 directory not found")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Test 7: pSRT 2.0 ê°€ì¤‘ì¹˜ í•©ê³„ ê²€ì¦
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def test_psrt_weights() -> None:
    """PSRT 2.0 ê°€ì¤‘ì¹˜ í•©ê³„ ê²€ì¦."""
    print("\n" + "=" * 60)
    print("Test 7: pSRT 2.0 Weight Validation")
    print("=" * 60)

    # ì„¤ì • íŒŒì¼ì—ì„œ ê°€ì¤‘ì¹˜ í™•ì¸
    config_path = PROJECT_ROOT / "config" / "pSRT-config.yaml"
    if config_path.exists():
        content = config_path.read_text()

        # ê°€ì¤‘ì¹˜ ì¶”ì¶œ (ê°œì„ ëœ íŒŒì‹±)
        weights = {}
        in_weights_section = False
        indent_level = 0

        for line in content.split("\n"):
            # final_pSRT_weights ì„¹ì…˜ ì‹œì‘ ê°ì§€
            if "final_pSRT_weights:" in line and not line.strip().startswith("#"):
                in_weights_section = True
                indent_level = len(line) - len(line.lstrip())
                continue

            if in_weights_section:
                # ë¹ˆ ì¤„ì´ë‚˜ ì£¼ì„ë§Œ ìˆëŠ” ì¤„ì€ ê±´ë„ˆë›°ê¸°
                stripped = line.strip()
                if not stripped or stripped.startswith("#"):
                    continue

                # ë‹¤ë¥¸ ì„¹ì…˜ìœ¼ë¡œ ë„˜ì–´ê°”ëŠ”ì§€ í™•ì¸ (ë“¤ì—¬ì“°ê¸° ê°ì†Œ)
                current_indent = len(line) - len(line.lstrip())
                if current_indent <= indent_level and ":" in line and not line.startswith(" "):
                    in_weights_section = False
                    continue

                # ê°€ì¤‘ì¹˜ í•­ëª© íŒŒì‹±
                if ":" in stripped and not stripped.startswith("#"):
                    parts = stripped.split(":")
                    if len(parts) >= 2:
                        key = parts[0].strip()
                        # ê°’ì—ì„œ ì£¼ì„ ì œê±°
                        val_str = parts[1].split("#")[0].strip()
                        try:
                            val = float(val_str)
                            weights[key] = val
                        except ValueError:
                            pass

        if weights:
            total = sum(weights.values())
            expected = 1.0
            if abs(total - expected) < 0.01:
                log_pass("pSRT weights sum", f"Sum = {total:.2f} (expected {expected})")
            else:
                log_fail("pSRT weights sum", f"Sum = {total:.2f} (expected {expected})")

            # ê°œë³„ ê°€ì¤‘ì¹˜ ì¶œë ¥
            for k, v in weights.items():
                print(f"   â””â”€ {k}: {v}")
        else:
            log_warn("pSRT weights", "Could not parse weights")
    else:
        log_fail("pSRT weights", "Config file not found")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Test 8: ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš° ìˆœì„œ ê²€ì¦
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def test_workflow_order() -> None:
    """ì—ì´ì „íŠ¸ ì‹¤í–‰ ìˆœì„œ ê²€ì¦."""
    print("\n" + "=" * 60)
    print("Test 8: Workflow Order Validation")
    print("=" * 60)

    # ì˜ˆìƒ ì›Œí¬í”Œë¡œìš° ìˆœì„œ (pSRT 2.0 í†µí•©)
    expected_order = [
        ("5.0", "signal-classifier", "STEEPS ë¶„ë¥˜ ë° ìš”ì•½ ìƒì„±"),
        ("5.3", "groundedness-verifier", "Phase 1: ê·¼ê±°ì„± ê²€ì¦"),
        ("5.5", "cross-validator", "Phase 2: êµì°¨ ê²€ì¦"),
        ("5.7", "confidence-evaluator", "pSRT 2.0 í†µí•© í‰ê°€"),
        ("5.9", "hallucination-detector", "Phase 4: í• ë£¨ì‹œë„¤ì´ì…˜ ê°ì§€"),
        ("6.0", "impact-analyzer", "ì˜í–¥ë„ ë¶„ì„"),
        ("7.0", "priority-ranker", "ìš°ì„ ìˆœìœ„ ì‚°ì •"),
        ("Post", "calibration-engine", "Phase 3: ì—­ì‚¬ì  ë³´ì •"),
    ]

    agents_dir = PROJECT_ROOT / ".claude" / "agents"

    for step, agent_name, description in expected_order:
        agent_path = agents_dir / f"{agent_name}.md"
        if agent_path.exists():
            content = agent_path.read_text()
            # ì›Œí¬í”Œë¡œìš° ë‹¨ê³„ ì–¸ê¸‰ í™•ì¸
            if step in content or "ë‹¨ê³„" in content:
                log_pass(f"Step {step}: {agent_name}", description)
            else:
                log_warn(f"Step {step}: {agent_name}", "Step number not in agent doc")
        else:
            log_fail(f"Step {step}: {agent_name}", "Agent file not found")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Main
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def main() -> int:
    """Run all E2E workflow validation tests."""
    print("\n" + "=" * 60)
    print("   pSRT 2.0 E2E Workflow Validation")
    print("   " + datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    print("=" * 60)

    # ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_agent_files_exist()
    test_agent_metadata()
    test_workflow_io_connections()
    test_config_files()
    test_history_database()
    test_actual_data()
    test_psrt_weights()
    test_workflow_order()

    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 60)
    print("   SUMMARY")
    print("=" * 60)

    passed = len(results["passed"])
    failed = len(results["failed"])
    warnings = len(results["warnings"])
    total = passed + failed + warnings

    print(f"\nâœ… Passed:   {passed}/{total}")
    print(f"âŒ Failed:   {failed}/{total}")
    print(f"âš ï¸  Warnings: {warnings}/{total}")

    if failed == 0:
        print("\nğŸ‰ All critical tests passed!")
        status = "PASS"
    else:
        print("\nâ›” Some tests failed. Please review.")
        status = "FAIL"

    # ê²°ê³¼ ì €ì¥
    output_path = PROJECT_ROOT / "tests" / "e2e-results.json"
    output_path.parent.mkdir(parents=True, exist_ok=True)

    with output_path.open("w") as f:
        json.dump(
            {
                "timestamp": datetime.now().isoformat(),
                "status": status,
                "summary": {"passed": passed, "failed": failed, "warnings": warnings},
                "results": results,
            },
            f,
            indent=2,
            ensure_ascii=False,
        )

    print(f"\nğŸ“„ Results saved to: {output_path}")

    return 0 if failed == 0 else 1


if __name__ == "__main__":
    exit(main())
